preprocessing:
  extract_prefix: true # split lemmas by prefix and suffix
  extract_suffix: false # REDUNDENT
  morph_code_only: false 
  flat_suff_person: true  # remove person-form indicator or not
  ng_min: 1  # min_ngram
  ng_max: 1  # max_ngram (must be larger than ng_min)
  pad: false # add <start>/<end> symbols at the begining/ending of verses
  to_remove: # morpholical pad_ledcodes to remove (Np = proper name, Ng = gentilic noun), 
             # see https://hb.openscriptures.org/parsing/HebrewMorphologyCodes.html
     - "FFF"
     #- Np     # noun proper
     #- Ng     # noun gentile
     #- Ac     # cardinal number
  to_replace: # morpholical pad_ledcodes to replace by a symbol
    - Ac # cardinal number
    - Ng # noun gentilic
    - Np # name proper
    #- Pp # Proposition personal
    #- Rd # preposition definite article
    # - Nc # noun comon
    # - Vq # verb
    
    
vocab:
  no_tokens: 3000  # most frequent tokens
  by_author: true  # most frequent by each author of the known_authors list

model:
  feat_reduction_method: "none" # options are: div_persuit, one_vs_many, none
  gamma: .35  # HC parameter (lower fruction of P-values to consider)
  stbl: true  # type of HC
  min_cnt: 1 
  n_fold: 10
  measures:   # list of discrepancy measures available
    - 'HC'
    #- 'Fisher'pipeline
    #- 'chisq'

known_authors:
  - Dtr
  - DtrH
  - P

unk_authors:
  - Ark1
  - Ark2
  - Late_Abraham
  - Gibea
  - Early_Jacob
  - Chr2
  - Chr1
  - Esth
  - Prov
  - Lev26

all_authors:
  - Dtr
  - DtrH
  - P
  - Ark1
  - Ark2
  - Late_Abraham
  - Gibea
  - Early_Jacob
  - Chr2
  - Chr1
  - Esth
  - Prov
  - Lev26

chunk_len_params:
  sampling_method: "verse"
  contiguous_chunk: "true"
  nMonte: 100
  chunk_lengths:
    - 5
    - 10
    - 15
    - 20
    - 25
    - 30
    - 40
    - 50
    - 60
    - 70
    - 80
    - 90
    - 100

report:
  value: 'HC' 
  #value: 'Fisher'
  #value: 'chisq'
  fig_path: 'data/08_reporting/Figs'
  min_length_to_report: 300 # only include texts of at least min_length words
  known_authors:
  - Dtr
  - DtrH
  - P
  
bootstrapping:
  nBS: 100
  value: 'HC'
  reduce_feature: None

sim_full: # These parameters are not in use, but make
          # sure that n is larger than max_no_docs_per_corpus. These parameters
          # required to simulate a different null distribution, e.g., by sampling 
          # text chunks from a contiguous piece of text
  n: 200
  min_length_to_consider: 300
  sampling_method: "doc_id"
  k_docs: 1
  sample_w_replacements: true
  sample_contiguous: false
  random: false
